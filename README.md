# Discrete Diffusion
---
- This project will attempt to implement the ideas from the *Simple and Effective Masked Diffusion Language Models* into the *Julia* with the final downstream goal of using for protein sequencing.
## Project Components

### Data Representation and Tokenisation
- Tokenisers work by 
- Tokenisation methods used in the article are for One Billion Words and GPT2 tokeniser for OpenWebText.

### Diffusion Transformers & Model Architecture

### Forward Masking Process

### Reverse Unmasking Process

#### SUBS - Substitution

### Loss Function

### Training of Model

## Packages to Learn
- Several packages and `Julia` concepts will be needed downstream 
	- `CUDA.jl`
	- `flux.jl`
	- `zygote.jl`